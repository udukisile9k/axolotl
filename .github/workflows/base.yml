name: ci-cd-base

on:
  push:
    branches:
      - "main-base"
      - "dev-base"

jobs:
  build-base:
    if: github.repository_owner == 'OpenAccess-AI-Collective'
    # this job needs to be run on self-hosted GPU runners...
    runs-on: self-hosted
    strategy:
      matrix:
        include:
          - cuda: "118"
            cuda_version: 11.8.0
            axolotl_extras:
          - cuda: "117"
            cuda_version: 11.7.0
            pytorch: 1.13.1
            axolotl_extras:
          - cuda: "118"
            cuda_version: 11.8.0
            pytorch: 2.0.0
            axolotl_extras: gptq
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Docker metadata
        id: metadata
        uses: docker/metadata-action@v3
        with:
          images: winglian/axolotl-base
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      - name: Build
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./docker/Dockerfile-base
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.metadata.outputs.tags }}-cu${{ matrix.cuda }}-${{ matrix.pytorch }}${{ matrix.axolotl_extras != '' && '-' || '' }}${{ matrix.axolotl_extras }}
          labels: ${{ steps.metadata.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            CUDA_VERSION=${{ matrix.cuda_version }}
            CUDA=${{ matrix.cuda }}
            PYTORCH_VERSION=${{ matrix.pytorch }}
            AXOLOTL_EXTRAS=${{ matrix.axolotl_extras }}
